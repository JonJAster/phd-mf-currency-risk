{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import progressbar as pb\n",
    "from custom_modules.helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Read Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filepart_str(filename_base, part_num, curr=None):\n",
    "    \"\"\"\n",
    "    Return a formatted filename string from a base string and a part\n",
    "    number.\n",
    "    \n",
    "    filename_base : str\n",
    "        The base string of the name of the data to be loaded.\n",
    "    part_num : int\n",
    "        The part number included in the name of the data to be loaded.\n",
    "    curr : \"local\" or \"usd\", default None\n",
    "        If provided, indicates that a choice of currency folder should\n",
    "        be included in the file directory string.\n",
    "    \"\"\"\n",
    "    \n",
    "    if curr is None:\n",
    "        full_base = filename_base\n",
    "    elif curr == \"usd\":\n",
    "        full_base = \"usd-returns\\\\\"+filename_base\n",
    "    elif curr == \"local\":\n",
    "        full_base = \"local-returns\\\\\"+filename_base\n",
    "    else:\n",
    "        raise ValueError(\"curr must be 'usd' or 'local'.\")\n",
    "    \n",
    "    output = (\n",
    "        \"..\\\\Data\\\\Raw Data\\\\Mutual Funds\\\\{base}\\\\\"\n",
    "         \"mf_{base}_part-{part}.csv\".format(base=full_base, part=part_num)\n",
    "    )\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfread(filename_base, exp_dtype=None, thousands=None, curr=None):\n",
    "    \"\"\"\n",
    "    Read all parts of a multi-part dataset by looping through part\n",
    "    numbers within a given directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename_base : str\n",
    "        The base string of the name of the data to be loaded.\n",
    "    exp_dtype : type, default None\n",
    "        If provided, sets the datatype of all columns to be loaded\n",
    "        except for the three left-most columns.\n",
    "    thousands : str, default None\n",
    "        If provided, indicates a thousands separator in the data to be\n",
    "        read.\n",
    "    curr : \"local\" or \"usd\", default None\n",
    "        If provided, indicates that a choice of currency folder should\n",
    "        be included in the file directory string.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : pd.DataFrame\n",
    "        A loaded dataframe containing all parts of the data present in\n",
    "        the given directory\n",
    "    \"\"\"\n",
    "        \n",
    "    # --- SET UP ---\n",
    "    # If any explicit datatypes are given, pull out the column names\n",
    "    # to declare which columns should be typed in the next read\n",
    "    if exp_dtype is not None:\n",
    "        col_names = pd.read_csv(filepart_str(filename_base, 1),\n",
    "                                nrows=0).columns\n",
    "        dict_dtypes = dict(zip(col_names[3:],\n",
    "                               [exp_dtype]*(col_names.size-3)))\n",
    "    else:\n",
    "        dict_dtypes = None\n",
    "        \n",
    "    # Add a folder for the choice of currency if necessary\n",
    "    if curr is None:\n",
    "        full_base = filename_base\n",
    "    elif curr == \"usd\":\n",
    "        full_base = \"usd-returns\\\\\"+filename_base\n",
    "    elif curr == \"local\":\n",
    "        full_base = \"local-returns\\\\\"+filename_base\n",
    "    else:\n",
    "        raise ValueError(\"curr must be 'usd' or 'local'.\")\n",
    "        \n",
    "    # --- READ FILES ---\n",
    "    # Read part one of the base data\n",
    "    try:\n",
    "        df_return = pd.read_csv(filepart_str(filename_base, 1, curr=curr),\n",
    "                                dtype=dict_dtypes, thousands=thousands)\n",
    "    except FileNotFoundError:\n",
    "        raise ValueError(\"{} is an invalid filename_base (no part \"\n",
    "                         \"one file in directory)\".format(filename_base))\n",
    "\n",
    "    # Initialise loop variables\n",
    "    i = 2  # Start on part 2\n",
    "    loading = True\n",
    "\n",
    "    while(loading):\n",
    "        try:\n",
    "            df_concat = pd.read_csv(filepart_str(filename_base, i, curr=curr),\n",
    "                                    dtype=dict_dtypes, thousands=thousands)\n",
    "        except FileNotFoundError:\n",
    "            # If the next part doesn't exist, turn off the loop\n",
    "            loading = False\n",
    "        else:\n",
    "            # Only concatenate again if new data was found\n",
    "            df_return = pd.concat([df_return, df_concat])\n",
    "            i += 1\n",
    "\n",
    "    return df_return.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Country Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the info dataframe from its parts, select only the columns for secid and country, and count the number of funds domiciled in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ozboy\\AppData\\Local\\Temp\\ipykernel_13116\\1140695005.py:63: DtypeWarning: Columns (313,344,357,384) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_concat = pd.read_csv(filepart_str(filename_base, i, curr=curr),\n"
     ]
    }
   ],
   "source": [
    "df_countries = dfread(\"info\").loc[:,\"SecId\":\"Domicile\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of funds is: 569375\n",
      "Display fundcount for a breakdown of funds domiciled in each country.\n"
     ]
    }
   ],
   "source": [
    "fundcount = (\n",
    "    df_countries.groupby(\"Domicile\").SecId.count().sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"The total number of funds is: {}\".format(fundcount.sum()))\n",
    "print(\"Display fundcount for a breakdown of funds domiciled in each country.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form groups of countries in roughly descending order of fund count such that every country is included in at most one group and every group has at most 65,000 funds in it unless it contains only one country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_groups = {\n",
    "    \"lux\": [\"Luxembourg\"],\n",
    "    \"kor\": [\"South Korea\"],\n",
    "    \"usa\": [\"United States\"],\n",
    "    \"can-chn-jpn\": [\"Canada\", \"China\", \"Japan\"],\n",
    "    \"irl-bra\": [\"Ireland\", \"Brazil\"],\n",
    "    \"gbr-fra-ind\": [\"United Kingdom\", \"France\", \"India\"],\n",
    "    \"esp-tha-aus-zaf-mex-aut-che\": [\n",
    "        \"Spain\", \"Thailand\", \"Australia\", \"South Africa\", \"Mexico\", \"Austria\",\n",
    "        \"Switzerland\"\n",
    "    ],\n",
    "    \"other\": [\n",
    "        \"Belgium\", \"Germany\", \"Chile\", \"Italy\", \"Taiwan\", \"Israel\",\n",
    "        \"Cayman Islands\", \"Liechtenstein\", \"Sweden\", \"Finland\", \"Hong Kong\",\n",
    "        \"Malaysia\", \"Denmark\", \"Guernsey\", \"Netherlands\", \"Norway\", \"Singapore\",\n",
    "        \"Indonesia\", \"New Zealand\", \"Jersey\", \"Malta\", \"Portugal\", \"Poland\",\n",
    "        \"Bermuda\", \"British Virgin Islands\", \"Hungary\", \"Mauritius\", \"Turkey\",\n",
    "        \"Saudi Arabia\", \"Philippines\", \"Namibia\", \"Greece\", \"Isle of Man\",\n",
    "        \"Andorra\", \"Slovenia\", \"Russian Federation\", \"Bahamas\", \"Iceland\",\n",
    "        \"Estonia\", \"Kuwait\", \"United Arab Emirates\", \"Cura√ßao\", \"Bahrain\",\n",
    "        \"Botswana\", \"Lithuania\", \"Latvia\", \"Czech Republic\", \"Monaco\",\n",
    "        \"Puerto Rico\", \"Gibraltar\", \"Colombia\", \"Argentina\", \"San Marino\",\n",
    "        \"St Vincent-Grenadines\", \"Oman\", \"Swaziland\", \"Lesotho\", \"Viet Nam\",\n",
    "        \"Barbados\", \"Kenya\", \"Lebanon\", \"Jordan\", \"Qatar\", \"Tunisia\", \"Samoa\",\n",
    "        \"US Virgin Islands\", \"Bulgaria\", \"Uganda\", \"Cyprus\",\n",
    "        \"Marshall Islands\", \"Netherlands Antilles\", \"Panama\", \"Ukraine\",\n",
    "        \"Pakistan\", \"Uruguay\", \"Vanuatu\", \"Peru\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_secids = dict()\n",
    "for i in country_groups:\n",
    "    group_mask = df_countries.Domicile.isin(country_groups[i])\n",
    "    group_secids[i] = df_countries.loc[group_mask, \"SecId\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to read each dataframe from its parts, partition that frame across countries, and then resave using the new partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countrysplit(filename_base, exp_dtype=None, thousands=None, curr=None):\n",
    "    \"\"\"\n",
    "    Read each combined DataFrame from its consituent parts, partition\n",
    "    that DataFrame across countries and resave using the new partition.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename_base : str\n",
    "        The base string of the name of the data to be loaded.\n",
    "    exp_dtype : type, default None\n",
    "        If provided, sets the datatype of all columns to be loaded\n",
    "        except for the three left-most columns.\n",
    "    thousands : str, default None\n",
    "        If provided, indicates a thousands separator in the data to be\n",
    "        read.\n",
    "    curr : \"local\" or \"usd\", default None\n",
    "        If provided, indicates that a choice of currency folder should\n",
    "        be included in the file directory string.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start a progress bar.\n",
    "    bar = pb.ProgressBar(max_value = len(group_secids)+1)\n",
    "    bar.update(0)\n",
    "        \n",
    "    # Load the full set of data and update the progress bar once.\n",
    "    df_active = dfread(filename_base, exp_dtype, thousands, curr)\n",
    "    bar.update(1)\n",
    "\n",
    "    \n",
    "    # Add a folder for the choice of currency if necessary\n",
    "    if curr is None:\n",
    "        full_base = filename_base\n",
    "    elif curr == \"usd\":\n",
    "        full_base = \"usd-returns\\\\\"+filename_base\n",
    "    elif curr == \"local\":\n",
    "        full_base = \"local-returns\\\\\"+filename_base\n",
    "    else:\n",
    "        raise ValueError(\"curr must be 'usd' or 'local'.\")\n",
    "        \n",
    "    # For all groups except \"other\", split off only those funds that\n",
    "    # come from countries belonging to that group, but for the \"other\"\n",
    "    # group also include any funds that have no domicile.\n",
    "    for i in group_secids:\n",
    "        dom_mask = df_active.SecId.isin(group_secids[i])\n",
    "        nondom_mask = ((i == \"other\")\n",
    "                       & ~(df_active.SecId.isin(df_countries.SecId)))\n",
    "        \n",
    "        df_split = (df_active[dom_mask | nondom_mask].copy())\n",
    "        \n",
    "        df_split.to_csv(\"..\\\\Data\\\\Raw Data\\\\Mutual Funds - Country Grouped\\\\\"\n",
    "                         \"{fbase}\\\\mf_{base}_{i}.csv\"\n",
    "                        .format(fbase=full_base, base=filename_base, i=i),\n",
    "                        index=False)\n",
    "        bar.update(bar.value+1)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (9 of 9) |##########################| Elapsed Time: 0:00:07 ETA:  00:00:00"
     ]
    }
   ],
   "source": [
    "countrysplit(\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (9 of 9) |##########################| Elapsed Time: 0:02:45 ETA:  00:00:00"
     ]
    }
   ],
   "source": [
    "countrysplit(\"monthly-costs\", np.float64, \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      "N/A% (0 of 9) |                          | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\Data\\\\Raw Data\\\\Mutual Funds\\\\monthly-gross-returns\\\\mf_monthly-gross-returns_part-1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcountrysplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmonthly-gross-returns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36mcountrysplit\u001b[1;34m(filename_base, exp_dtype, thousands, curr)\u001b[0m\n\u001b[0;32m     23\u001b[0m bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Load the full set of data and update the progress bar once.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m df_active \u001b[38;5;241m=\u001b[39m \u001b[43mdfread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Add a folder for the choice of currency if necessary\u001b[39;00m\n",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36mdfread\u001b[1;34m(filename_base, exp_dtype, thousands, curr)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# --- SET UP ---\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# If any explicit datatypes are given, pull out the column names\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# to declare which columns should be typed in the next read\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exp_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m     col_names \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepart_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     33\u001b[0m     dict_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(col_names[\u001b[38;5;241m3\u001b[39m:],\n\u001b[0;32m     34\u001b[0m                            [exp_dtype]\u001b[38;5;241m*\u001b[39m(col_names\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m)))\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\phd\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\phd\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\phd\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\phd\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\phd\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\phd\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\Data\\\\Raw Data\\\\Mutual Funds\\\\monthly-gross-returns\\\\mf_monthly-gross-returns_part-1.csv'"
     ]
    }
   ],
   "source": [
    "countrysplit(\"monthly-gross-returns\", np.float64, \",\", \"usd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrysplit(\"monthly-gross-returns\", np.float64, \",\", \"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrysplit(\"monthly-net-returns\", np.float64, \",\", \"usd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrysplit(\"monthly-net-returns\", np.float64, \",\", \"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (9 of 9) |##########################| Elapsed Time: 0:01:25 ETA:  00:00:00"
     ]
    }
   ],
   "source": [
    "countrysplit(\"monthly-morningstar-category\", object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrysplit(\"monthly-net-assets\", np.float64, \",\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
