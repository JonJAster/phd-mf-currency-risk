{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To practice writing performant Julia code I am attempting to improve the speed of part 1. As a reminder, the terminal output after the last run was:\n",
    "\n",
    "        Processing folder: info\n",
    "        Finished in 4.35 seconds\n",
    "        Processing folder: local-monthly-gross-returns\n",
    "        Finished in 130.5 seconds\n",
    "        Processing folder: local-monthly-net-returns\n",
    "        Finished in 148.06 seconds\n",
    "        Processing folder: monthly-costs\n",
    "        Finished in 63.1 seconds\n",
    "        Processing folder: monthly-morningstar-category\n",
    "        Finished in 467.8 seconds\n",
    "        Processing folder: monthly-net-assets\n",
    "        Finished in 237.36 seconds\n",
    "        Processing folder: usd-monthly-gross-returns\n",
    "        Finished in 85.24 seconds\n",
    "        Processing folder: usd-monthly-net-returns\n",
    "        Finished in 100.15 seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total runtime of the script (missing the time taken to load the info dataframe initially), then is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.61 minutes\n"
     ]
    }
   ],
   "source": [
    "println(round((4.35+130.5+148.06+63.1+467.8+237.36+85.24+100.15)/60, digits=2), \" minutes\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first change made is to employ parallel processing through @threads. The new terminal output is:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I lost the terminal output after the first run because I had to stop it partway through, but had recorded two of the times manually. It looked something like:\n",
    "\n",
    "        Regrouping files...\n",
    "        Processed folder info in 12.6 seconds\n",
    "        Processed folder monthly-costs in 1412.8 seconds\n",
    "        Processed folder monthly-usd-gross-returns in 1730.4 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monthly-costs took 23.55 minutes\n",
      "monthly-usd-gross-returns took 28.84 minutes\n"
     ]
    }
   ],
   "source": [
    "println(\"monthly-costs took $(round(1412.8/60, digits=2)) minutes\")\n",
    "println(\"monthly-usd-gross-returns took $(round(1730.4/60, digits=2)) minutes\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio of time for usd-gross-returns to time for monthly-costs remained roughly the same, but took 22x as long, so there was no benefit to parallelism at all and the overtime time taken was substantially increased."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a measure of the speed-up obtained simply by allowing CSV.read to run multithreaded, here is the terminal output from running the original code with number of threads increased to auto in settings:\n",
    "\n",
    "        Processed folder info in 4.35 seconds\n",
    "        Processed folder local-monthly-gross-returns in 109.61 seconds\n",
    "        Processed folder local-monthly-net-returns in 142.17 seconds\n",
    "        Processed folder monthly-costs in 59.3 seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I stopped the code after getting the first three examples. Looks like between 5-20 seconds was saved by utiliting multithreading."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote a new script to clean all the csv files to make future loads faster, but it took almost as long (11 minutes total) and would not likely save more than that amount of time in the next step. Terminal output:\n",
    "\n",
    "        Cleaning csv files...\n",
    "        Finished cleaning info in 15.46 seconds.\n",
    "        Finished cleaning local-monthly-gross-returns in 141.7 seconds.\n",
    "        Finished cleaning local-monthly-net-returns in 149.93 seconds.\n",
    "        Finished cleaning monthly-costs in 78.25 seconds.\n",
    "        Finished cleaning monthly-morningstar-category in 132.58 seconds.\n",
    "        Finished cleaning monthly-net-assets in 294.68 seconds.\n",
    "        Finished cleaning usd-monthly-gross-returns in 135.9 seconds.\n",
    "        Finished cleaning usd-monthly-net-returns in 175.42 seconds.\n",
    "        Finished cleaning all csv files in 1123.93 seconds."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to clean the files directly without using CSV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was able to get the empty quotes removed with very little overhead. Terminal output:\n",
    "\n",
    "        Copying csv files...\n",
    "        Finished copying csv files in 14.19 seconds.\n",
    "        Cleaning csv files...\n",
    "        Finished cleaning info in 0.3 seconds.\n",
    "        Finished cleaning local-monthly-gross-returns in 35.57 seconds.\n",
    "        Finished cleaning local-monthly-net-returns in 32.29 seconds.\n",
    "        Finished cleaning monthly-costs in 16.93 seconds.\n",
    "        Finished cleaning monthly-morningstar-category in 26.62 seconds.\n",
    "        Finished cleaning monthly-net-assets in 20.98 seconds.\n",
    "        Finished cleaning usd-monthly-gross-returns in 20.91 seconds.\n",
    "        Finished cleaning usd-monthly-net-returns in 18.77 seconds.\n",
    "        Finished cleaning all csv files in 186.57 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the new cleaning code terminal output after correcting it to truncate the file after cleaning and retrying IO operations until success or timeout:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Copying csv files...\n",
    "        Finished copying csv files in 39.83 seconds.\n",
    "        Cleaning csv files...\n",
    "        Finished cleaning info in 0.56 seconds.\n",
    "        Finished cleaning local-monthly-gross-returns in 27.12 seconds.\n",
    "        Finished cleaning local-monthly-net-returns in 24.45 seconds.\n",
    "        Finished cleaning monthly-costs in 13.28 seconds.\n",
    "        Finished cleaning monthly-morningstar-category in 32.39 seconds.\n",
    "        Finished cleaning monthly-net-assets in 27.4 seconds.\n",
    "        Finished cleaning usd-monthly-gross-returns in 16.97 seconds.\n",
    "        Finished cleaning usd-monthly-net-returns in 25.15 seconds.\n",
    "        Finished cleaning all csv files in 207.16 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After three days, I've finally managed to get multithreaded CSV reading to work on the full set of CSVs. Now that multithreading is active, here is the new terminal output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Regrouping files...\n",
    "        Processed folder info in 4.18 seconds\n",
    "        Processed folder local-monthly-gross-returns in 116.24 seconds\n",
    "        Processed folder local-monthly-net-returns in 145.8 seconds\n",
    "        Processed folder monthly-costs in 73.6 seconds\n",
    "        Processed folder monthly-morningstar-category in 375.51 seconds\n",
    "        Processed folder monthly-net-assets in 384.62 seconds\n",
    "        Processed folder usd-monthly-gross-returns in 83.62 seconds\n",
    "        Processed folder usd-monthly-net-returns in 101.82 seconds\n",
    "        Finished refining mutual fund data in 1302.07 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This original terminal output for this script was:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Processing folder: info\n",
    "        Finished in 4.35 seconds\n",
    "        Processing folder: local-monthly-gross-returns\n",
    "        Finished in 130.5 seconds\n",
    "        Processing folder: local-monthly-net-returns\n",
    "        Finished in 148.06 seconds\n",
    "        Processing folder: monthly-costs\n",
    "        Finished in 63.1 seconds\n",
    "        Processing folder: monthly-morningstar-category\n",
    "        Finished in 467.8 seconds\n",
    "        Processing folder: monthly-net-assets\n",
    "        Finished in 237.36 seconds\n",
    "        Processing folder: usd-monthly-gross-returns\n",
    "        Finished in 85.24 seconds\n",
    "        Processing folder: usd-monthly-net-returns\n",
    "        Finished in 100.15 seconds  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were extremely minimal performance gains on all files except for monthly-net-assets, which actually got substantially worse. The total time, as a result, is larger with multithreading than without."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiler shows that 68% of the time spent is to save the CSVs, 14% concatenating the data, and only 3% reading the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With pooled concatenation instead of serial concatenation:\n",
    "\n",
    "        Regrouping files...\n",
    "        Processed folder info in 4.1 seconds\n",
    "        Processed folder local-monthly-gross-returns in 104.27 seconds\n",
    "        Processed folder local-monthly-net-returns in 148.02 seconds\n",
    "        Processed folder monthly-costs in 67.38 seconds\n",
    "        Processed folder monthly-morningstar-category in 269.78 seconds\n",
    "        Processed folder monthly-net-assets in 310.17 seconds\n",
    "        Processed folder usd-monthly-gross-returns in 75.4 seconds\n",
    "        Processed folder usd-monthly-net-returns in 98.71 seconds\n",
    "        Finished refining mutual fund data in 1093.77 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the output of the cleaning code with the addition of cleaning for thousand separating commas:\n",
    "\n",
    "        Copying csv files...\n",
    "        Finished copying csv files in 22.09 seconds.\n",
    "        Cleaning csv files...\n",
    "        Finished cleaning info in 0.72 seconds.\n",
    "        Finished cleaning local-monthly-gross-returns in 36.03 seconds.\n",
    "        Finished cleaning local-monthly-net-returns in 28.44 seconds.\n",
    "        Finished cleaning monthly-costs in 15.35 seconds.\n",
    "        Finished cleaning monthly-morningstar-category in 25.19 seconds.\n",
    "        Finished cleaning monthly-net-assets in 25.53 seconds.\n",
    "        Finished cleaning usd-monthly-gross-returns in 18.55 seconds.\n",
    "        Finished cleaning usd-monthly-net-returns in 17.33 seconds.\n",
    "        Finished cleaning all csv files in 189.22 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It runs in roughly the same amount of time, with most stages taking only 1-2 seconds longer than without that part. Still 50% of the time is spent removing empty double-quotes. I should check to see if this is necessary anymore."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without thousands separators, monthly-net-assets runs substantially faster:\n",
    "\n",
    "        Regrouping files...\n",
    "        Processed folder info in 3.99 seconds\n",
    "        Processed folder local-monthly-gross-returns in 103.67 seconds\n",
    "        Processed folder local-monthly-net-returns in 146.86 seconds\n",
    "        Processed folder monthly-costs in 72.71 seconds\n",
    "        Processed folder monthly-morningstar-category in 271.08 seconds\n",
    "        Processed folder monthly-net-assets in 77.28 seconds\n",
    "        Processed folder usd-monthly-gross-returns in 119.39 seconds\n",
    "        Processed folder usd-monthly-net-returns in 131.19 seconds\n",
    "        Finished refining mutual fund data in 942.55 seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test if the removal of double quotes is still necessary, I've taken it out of the cleaning step. Here is the new output of the cleaning step:\n",
    "\n",
    "        Copying csv files...\n",
    "        Finished copying csv files in 45.13 seconds.\n",
    "        Cleaning csv files...\n",
    "        Finished cleaning info in 0.72 seconds.\n",
    "        Finished cleaning local-monthly-gross-returns in 8.07 seconds.\n",
    "        Finished cleaning local-monthly-net-returns in 7.42 seconds.\n",
    "        Finished cleaning monthly-costs in 4.62 seconds.\n",
    "        Finished cleaning monthly-morningstar-category in 10.16 seconds.\n",
    "        Finished cleaning monthly-net-assets in 11.16 seconds.\n",
    "        Finished cleaning usd-monthly-gross-returns in 5.16 seconds.\n",
    "        Finished cleaning usd-monthly-net-returns in 5.41 seconds.\n",
    "        Finished cleaning all csv files in 97.87 seconds."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of the grouping step:\n",
    "\n",
    "        Regrouping files...\n",
    "        Processed folder info in 4.08 seconds\n",
    "        Processed folder local-monthly-gross-returns in 102.64 seconds\n",
    "        Processed folder local-monthly-net-returns in 141.61 seconds\n",
    "        Processed folder monthly-costs in 54.09 seconds\n",
    "        Processed folder monthly-morningstar-category in 182.64 seconds\n",
    "        Processed folder monthly-net-assets in 73.36 seconds\n",
    "        Processed folder usd-monthly-gross-returns in 117.78 seconds\n",
    "        Processed folder usd-monthly-net-returns in 126.56 seconds\n",
    "        Finished refining mutual fund data in 817.61 seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've renumbered the steps to include the cleaning step as the new step 1. With that in mind, the total runtime of steps 1 and 2 is now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"15.26 minutes\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"$(round((97.87+817.61)/60, digits=2)) minutes\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is 5 minutes faster than the original implementation of what is now step 2. Some of that speed up occured because monthly-morningstar-category processing time was reduced by the retention of empty double quotes. I'm not sure why, but won't spend any time testing it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've just come back and updated the grouping script so that it deletes empty rows and empty columns. Here is the terminal output of that step now:\n",
    "\n",
    "        Regrouping files...\n",
    "        Processed folder info in 2.99 seconds\n",
    "        Processed folder local-monthly-gross-returns in 82.84 seconds\n",
    "        Processed folder local-monthly-net-returns in 144.57 seconds\n",
    "        Processed folder monthly-costs in 43.51 seconds\n",
    "        Processed folder monthly-morningstar-category in 240.36 seconds\n",
    "        Processed folder monthly-net-assets in 91.52 seconds\n",
    "        Processed folder usd-monthly-gross-returns in 127.74 seconds\n",
    "        Processed folder usd-monthly-net-returns in 136.24 seconds\n",
    "        Finished refining mutual fund data in 870.68 seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some runs were faster, some slower, but it took only 1 extra minute and will allow for easier processing in the next stage."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on I realised that cleaning newlines was no longer going to work, so I edited out the cleaning script altogether. The rerouted regrouping script output is now:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Regrouping files...\n",
    "        Processed folder info in 4.45 seconds\n",
    "        Processed folder local-monthly-gross-returns in 87.01 seconds\n",
    "        Processed folder local-monthly-net-returns in 146.95 seconds\n",
    "        Processed folder monthly-costs in 47.34 seconds\n",
    "        Processed folder monthly-morningstar-category in 210.86 seconds\n",
    "        Processed folder monthly-net-assets in 342.48 seconds\n",
    "        Processed folder usd-monthly-gross-returns in 66.58 seconds\n",
    "        Processed folder usd-monthly-net-returns in 98.45 seconds\n",
    "        Finished refining mutual fund data in 1020.07 seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were no significant slowdowns except for in monthly-net-assets. I forgot that the cleaning code also cleans the thousands separators, so I'll have to add that back into the regrouping code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I edited to remove the thousands seperators in place and reran a segment of the script so that only monthly-net-assets was processed. The output was:\n",
    "\n",
    "        Regrouping files...\n",
    "        Processed folder info in 3.02 seconds\n",
    "        Processed folder monthly-net-assets in 71.43 seconds\n",
    "        Finished refining mutual fund data in 75.04 seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that timing, the total runtime would have been 748.95 seconds, or 12.5 minutes. It seems that the cleaning script was never needed to begin with."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out there is at least one other file that contains a thousands separating comma in at least one spot. Without spending the time to devise a way to tell if the removal is necessary, I changed so that thousands separating commas are removed from all data. It increased the runtime to:\n",
    "\n",
    "        Regrouping files...\n",
    "        Processed folder info in 4.63 seconds\n",
    "        Processed folder local-monthly-gross-returns in 104.02 seconds\n",
    "        Processed folder local-monthly-net-returns in 188.06 seconds\n",
    "        Processed folder monthly-costs in 60.86 seconds\n",
    "        Processed folder monthly-morningstar-category in 268.3 seconds\n",
    "        Processed folder monthly-net-assets in 99.16 seconds\n",
    "        Processed folder usd-monthly-gross-returns in 120.9 seconds\n",
    "        Processed folder usd-monthly-net-returns in 158.46 seconds\n",
    "        Finished refining mutual fund data in 1020.94 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
