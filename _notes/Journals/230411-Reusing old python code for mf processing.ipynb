{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've run out of time to rewrite the mf processing script in julia, and I will be bringing across my existing python script from notebooks to this project instead.\n",
    "\n",
    "First, after downloading some more data from Morningstar, I actually did run into a problem when trying to do my csv cleaning step by relying on the formatting of the end-of-lines in the existing Morningstar data. I'm going to edit the code so that it start on the first step again without any cleaning of the raw files, as that's the fastest way I can see getting to the end of the project in the face of this hurdle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I forgot that the cleaning code also cleans thousands separators on the net assets data. Before adjusting for that, here is the output of the monthly-net-assets read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "df_before_adjustment = CSV.read(\"../../data/prepared/mutual-funds/monthly-net-assets/mf_monthly-net-assets_other.csv\", DataFrame)\n",
    "\n",
    "first(df_before_adjustment, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_before_adjustment[findfirst(!ismissing, df_before_adjustment[!, 300]), 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after_adjustment = CSV.read(\"../../data/prepared/mutual-funds/monthly-net-assets/mf_monthly-net-assets_other.csv\", DataFrame)\n",
    "\n",
    "first(df_after_adjustment, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after_adjustment[findfirst(!ismissing, df_after_adjustment[!, 300]), 300]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm trying to find why there are some missing fundid entries in the regrouped files, but it doesn't look like there are any missing in the original files from what I can tell so far. I will look at the regrouped files again and find an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELD_FOLDERS = [\n",
    "    \"info\", \"local-monthly-gross-returns\", \"local-monthly-net-returns\", \"monthly-costs\",\n",
    "    \"monthly-morningstar-category\", \"monthly-net-assets\", \"usd-monthly-gross-returns\",\n",
    "    \"usd-monthly-net-returns\"\n",
    "]\n",
    "\n",
    "dataset_lux = DataFrame[]\n",
    "for folder in FIELD_FOLDERS\n",
    "    filestring = joinpath(\"../../data/prepared/mutual-funds\", folder, \"mf_$(folder)_lux.csv\")\n",
    "    df = CSV.read(filestring, DataFrame)\n",
    "    push!(dataset_lux, df)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if any fundids are missing in the dfs in dataset_other\n",
    "for (i,df) in enumerate(dataset_other)\n",
    "    num_missing = sum(ismissing, df[!, :fundid])\n",
    "    println(\"missing fundids in df$i: $num_missing\")\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
